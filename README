
Creating directories in hadoop file system

$ hadoop fs -mkdir -p /user/paolo/capstone/airline_origin_destination/raw_data/

Put origin-destination data in hadoop filesystem

$ hadoop fs -put ./raw_data/* /user/paolo/capstone/airline_origin_destination/raw_data/

Listing directory contents

$ hadoop fs -ls /user/paolo/capstone/airline_origin_destination/

Call a pig script passing input directory and output file

$ pig -x mapreduce -p input=/user/paolo/capstone/airline_origin_destination/raw_data/ \
  -p output=/user/paolo/capstone/airline_origin_destination/top_10 \
  -p filtered=/user/paolo/capstone/airline_origin_destination/filtered_data/ \
  load_origin_destination.pig

List resuts in hadoop FS:

$ hadoop fs -ls /user/paolo/capstone/airline_origin_destination/top_10/
$ hadoop fs -ls /user/paolo/capstone/airline_origin_destination/filtered_data/

Dump results on screeen:

$ hadoop fs -cat /user/paolo/capstone/airline_origin_destination/top_10/part-r-00000
$ hadoop fs -cat /user/paolo/capstone/airline_origin_destination/filtered_data/part-m-00000 | head
